# Alchemyst AI â€” Vercel AI SDK Integration

**Alchemyst AI** is the **context layer** for your LLM applications â€” it remembers, reasons, and injects contextual intelligence automatically into every call.
This package provides a seamless integration with [**Vercelâ€™s AI SDK**](https://ai-sdk.dev) to enhance your Gen-AI apps with **memory**, **retrieval**, and **context-aware toolchains** â€” all through a single line of configuration.

---

## ðŸš€ Installation

```bash
npm install @alchemystai/aisdk
# or
yarn add @alchemystai/aisdk
#or
pnpm add @alchemystai/aisdk
# or
bun add @alchemystai/aisdk

```

---

## âš¡ Quick Start

Hereâ€™s how to plug Alchemyst AI into your `ai` SDK call in **one line**:

```typescript
import { streamText } from 'ai';
import { alchemystTools } from '@alchemystai/aisdk';

const result = await streamText({
  model: "gpt-5-nano",
  prompt: "Remember that my name is Alice",
  tools: alchemystTools("YOUR_ALCHEMYST_AI_KEY", true, true)
});
```

This automatically attaches the **Alchemyst Context Engine** to your model call â€” enabling persistent memory and context-aware generation across sessions.

---

## ðŸ§© API Reference

### `alchemystTools(apiKey: string, enableMemory?: boolean, enableRetrieval?: boolean)`

| Parameter         | Type      | Default | Description                                             |
| ----------------- | --------- | ------- | ------------------------------------------------------- |
| `apiKey`          | `string`  | â€”       | Your **Alchemyst AI API key**. Required.                |
| `enableMemory`    | `boolean` | `true`  | Enables contextual memory between user sessions.        |
| `enableRetrieval` | `boolean` | `true`  | Enables semantic retrieval from your connected sources. |

Returns an object compatible with the **`tools`** parameter of the `ai` SDK functions (`streamText`, `generateText`, `streamObject`, etc.).

---

## ðŸ§  What It Does

Once integrated, Alchemyst AI automatically:

* Persists **context** across user sessions.
* Augments prompts with **retrieved knowledge** from your Alchemyst AI workspace.
* Supports **custom tool functions** for domain-specific reasoning.
* Runs entirely **server-side** â€” no extra infrastructure required.

---

## ðŸ’¡ Example: Contextual Chatbot

```typescript
import { streamText } from 'ai';
import { alchemystTools } from '@alchemystai/aisdk';

export async function POST(req: Request) {
  const { messages } = await req.json();

  const response = await streamText({
    model: 'gpt-5-nano',
    messages,
    tools: alchemystTools(process.env.ALCHEMYST_API_KEY!, true, true),
  });

  return response.toAIStreamResponse();
}
```

With this, your AI app will:

* Remember previous user messages (via Alchemyst context memory)
* Retrieve relevant knowledge chunks
* Enrich every prompt dynamically before sending it to the model

---

## ðŸ”’ Environment Variables

Set your API key in your environment:

```bash
ALCHEMYST_API_KEY=sk-xxxxxx
```

Then reference it in your code as:

```typescript
alchemystTools(process.env.ALCHEMYST_API_KEY!);
```

---

## ðŸ§° Supported SDK Methods

Alchemyst AI integrates with all Vercel AI SDK entry points:

| SDK Function     | Supported | Notes                           |
| ---------------- | --------- | ------------------------------- |
| `streamText`     | âœ…         | Real-time streaming generation  |
| `generateText`   | âœ…         | Synchronous generation          |
| `streamObject`   | âœ…         | Structured JSON output          |
| `generateObject` | âœ…         | Non-streaming structured output |

---

## ðŸ§ª Example with Retrieval Off

```typescript
const result = await streamText({
  model: "gpt-5-nano",
  prompt: "Hello there!",
  tools: alchemystTools("YOUR_ALCHEMYST_AI_KEY", true, false),
});
```

---

## ðŸ“œ License

MIT Â© 2025 [Alchemyst AI](https://getalchemystai.com)

